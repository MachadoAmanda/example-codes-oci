{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "728353a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************Chat Result**************************\n",
      "{'status': 200, 'headers': {'content-type': 'application/json', 'opc-request-id': '8B9CED413DBB45DFB5503ECB593BF068/E3D961107095BF85EA7033F100FAC21B/DDA06D6DED277636DB503566E9590B3F', 'content-encoding': 'gzip', 'content-length': '465'}, 'data': {\n",
      "  \"chat_response\": {\n",
      "    \"api_format\": \"GENERIC\",\n",
      "    \"choices\": [\n",
      "      {\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"index\": 0,\n",
      "        \"logprobs\": {\n",
      "          \"text_offset\": null,\n",
      "          \"token_logprobs\": null,\n",
      "          \"tokens\": null,\n",
      "          \"top_logprobs\": null\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"content\": [\n",
      "            {\n",
      "              \"text\": \"Nesta imagem, temos uma pessoa se auto fotografando e, atrás dela, um animal. Esse animal parece ser um lhamas, mamífero pertencente à família Camelidae, originário da América do Sul.\",\n",
      "              \"type\": \"TEXT\"\n",
      "            }\n",
      "          ],\n",
      "          \"name\": null,\n",
      "          \"role\": \"ASSISTANT\",\n",
      "          \"tool_calls\": []\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    \"time_created\": \"2025-08-26T13:49:36.090000+00:00\"\n",
      "  },\n",
      "  \"model_id\": \"ocid1.generativeaimodel.oc1.sa-saopaulo-1.amaaaaaask7dceyalwceqwzlywqqxfzz3grpzjr42fej5qlybhu2d666oz4q\",\n",
      "  \"model_version\": \"1.0.0\"\n",
      "}, 'request': <oci.request.Request object at 0x0000022F8D127ED0>, 'next_page': None, 'request_id': '8B9CED413DBB45DFB5503ECB593BF068/E3D961107095BF85EA7033F100FAC21B/DDA06D6DED277636DB503566E9590B3F'}\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "# Copyright (c) 2023, Oracle and/or its affiliates.  All rights reserved.\n",
    "# This software is dual-licensed to you under the Universal Permissive License (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl or Apache License 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose either license.\n",
    "\n",
    "##########################################################################\n",
    "# chat_demo.py\n",
    "# Supports Python 3\n",
    "##########################################################################\n",
    "# Info:\n",
    "# Get texts from LLM model for given prompts using OCI Generative AI Service.\n",
    "##########################################################################\n",
    "# Application Command line(no parameter needed)\n",
    "# python chat_demo.py\n",
    "##########################################################################\n",
    "import oci\n",
    "\n",
    "# Setup basic variables\n",
    "# Auth Config\n",
    "# TODO: Please update config profile name and use the compartmentId that has policies grant permissions for using Generative AI Service\n",
    "compartment_id = \"ocid1.compartment.oc1..aaaaaaaa3x7n7wwfnghe4imvt3niwo76wgqv6ecn2iadiwoph73jjowbhbna\"\n",
    "CONFIG_PROFILE = \"SAOPAULO\"\n",
    "config = oci.config.from_file('~/.oci/config', CONFIG_PROFILE)\n",
    "\n",
    "# Service endpoint\n",
    "endpoint = \"https://inference.generativeai.sa-saopaulo-1.oci.oraclecloud.com\"\n",
    "\n",
    "generative_ai_inference_client = oci.generative_ai_inference.GenerativeAiInferenceClient(config=config, service_endpoint=endpoint, retry_strategy=oci.retry.NoneRetryStrategy(), timeout=(10,240))\n",
    "chat_detail = oci.generative_ai_inference.models.ChatDetails()\n",
    "\n",
    "###### Código adicionado para suporte a imagem ######\n",
    "import base64\n",
    "import json\n",
    "\n",
    "\n",
    "# Sua imagem\n",
    "image_content = \"demo-image.jpeg\"\n",
    "\n",
    "# Transforma a imagem em base64\n",
    "try:\n",
    "    with open(image_content, \"rb\") as image_file:\n",
    "        image_data = image_file.read()\n",
    "    base64_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "    base64_image_url = f\"data:image/jpeg;base64,{base64_image}\"\n",
    "except oci.exceptions.ServiceError as e:\n",
    "    raise ValueError(f\"Erro ao acessar a imagem\")\n",
    "    \n",
    "\n",
    "# Configuração do conteúdo da imagem\n",
    "imagem = oci.generative_ai_inference.models.ImageContent()\n",
    "image_url_content = oci.generative_ai_inference.models.ImageUrl()\n",
    "image_url_content.url = base64_image_url\n",
    "imagem.image_url = image_url_content\n",
    "\n",
    "# Configuração do conteúdo de texto\n",
    "texto = oci.generative_ai_inference.models.TextContent()\n",
    "texto.text = \"O que tem nesta imagem?\"\n",
    "\n",
    "# Configuração da mensagem do usuário\n",
    "message = oci.generative_ai_inference.models.UserMessage()\n",
    "message.role = \"USER\"\n",
    "message.content = [texto, imagem]\n",
    "#################################################################\n",
    "\n",
    "chat_request = oci.generative_ai_inference.models.GenericChatRequest()\n",
    "chat_request.api_format = oci.generative_ai_inference.models.BaseChatRequest.API_FORMAT_GENERIC\n",
    "chat_request.messages = [message]\n",
    "chat_request.max_tokens = 600\n",
    "chat_request.temperature = 1\n",
    "chat_request.frequency_penalty = 0\n",
    "chat_request.presence_penalty = 0\n",
    "chat_request.top_p = 0.75\n",
    "\n",
    "\n",
    "\n",
    "chat_detail.serving_mode = oci.generative_ai_inference.models.OnDemandServingMode(model_id=\"ocid1.generativeaimodel.oc1.sa-saopaulo-1.amaaaaaask7dceyalwceqwzlywqqxfzz3grpzjr42fej5qlybhu2d666oz4q\")\n",
    "chat_detail.chat_request = chat_request\n",
    "chat_detail.compartment_id = compartment_id\n",
    "\n",
    "chat_response = generative_ai_inference_client.chat(chat_detail)\n",
    "\n",
    "# Print result\n",
    "print(\"**************************Chat Result**************************\")\n",
    "print(vars(chat_response))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
